# AI Workflow Taxonomy and Naming Convention

## 1. Introduction & Purpose

Please consider the following taxonomy for classifying various AI generation workflows. Its purpose is to loosely categorize and encourage simplistic single-purpose workflow steps which can provide abstract characterizations of functional behavior. In particular, these will be used to classify and abstractly define ComfyUI and python script workflows for AI generation and curation.

The goal is to build a list of distinctive tasks that would likely require functionally-different workflows, rather than being semantic or stylistic differences.

## 2. Format Categories

The core categories represent distinct types of data commonly used in AI workflows:

*   **T** (text)
*   **I** (image)
*   **V** (video)
*   **M** (mesh)
*   **S** (sound/speech) - *Note: Standardized from 'A' used in earlier drafts.*
*   **C** (command/code) - Refers to code/commands as *data* (input/output), distinct from the workflow's own execution logic or configuration.
*   **D** (data, structured text)
*   **G** (game, interactive media)
*   **R** (robotics, real-world) - *Note: This category relates to controlling or interacting with physical systems or processes.*

In general, we refer to any category as "X".

### 2.1. Scale Modifiers (Singular vs. Multiple/Large)

Each category may have additional nuance based on scale:

*   **X** (singular): Represents a single instance or small scale (e.g., a singular image, a short text prompt).
*   **X+** (multiple/large): Represents multiple instances or large scale (e.g., very large images, batches of images, a large text corpus, a complex codebase).

**Examples:**

*   **T** vs. **T+**: A single prompt (T) vs. a batch of documents or a whole book (T+).
*   **I** vs. **I+**: A single photo (I) vs. a dataset of 1000 images or a gigapixel panorama (I+).
*   **V** vs. **V+**: A single video clip (V) vs. an entire library of clips or a long continuous stream (V+).
*   **S** vs. **S+**: A single sound file (S) vs. an album of songs or a 10-hour lecture (S+).
*   **M** vs. **M+**: A single 3D object (M) vs. a complex scene with many objects or multiple distinct meshes (M+).
*   **C** vs. **C+**: A single script or function (C) vs. a large codebase with many files (C+).
*   **D** vs. **D+**: A single CSV file or JSON object (D) vs. multiple datasets or a multi-gigabyte database (D+).
*   **G** vs. **G+**: A single game level or scenario (G) vs. a franchise or a massive open-world environment (G+).

Tasks involving **X+** often imply batch processing, handling of larger data structures, or iterative operations not required for singular **X** tasks.

### 2.2. Common Flags

Additional flags can modify the workflow description:

*   **Live**: Includes realtime, streaming, or interactive aspects.
*   **Fast**: Indicates a particularly speedy version, usually lower fidelity.
*   **Secure**: Indicates encrypted inputs/outputs or security-oriented processing.

## 3. Naming Conventions & Workflow Decomposition

### 3.1. Naming Structure

Workflows are named using the shorthand designation first (incorporating scale via `+`), followed by any relevant flags (like `_Live`, `_Fast`, `_Secure`), and finally any specifics of the workflow technique or model used.

**Structure:** `X[+]2Y[+]_Flag1_Flag2_SpecificTechnique`

*   **Base Shorthand:** `X2Y` (e.g., `I2T` for Image-to-Text)
*   **Longform:** `InputFormat_to_OutputFormat` (e.g., `Image_to_Text`)
*   **Scale Modifiers:** Use `+` on input (X) or output (Y) or both, as needed (e.g., `I+2T`, `T2I+`, `T+2I+`).
*   **Flags:** Append flags using underscores after the base X2Y notation. Multiple flags can be chained (e.g., `_Fast`, `_Live`, `_Fast_Live`).
*   **Specifics:** Add further descriptive terms or model names at the end, separated by underscores.
*   **Left-to-Right Importance:** The leftmost term is the most important general classifiers, with the rightmost being the most specific nuances.  This goes for tags too.
*   **Dates, Versions, etc:** Only if necessary, append dates, versions, or other metadata to the end of the name.
*   **Generators & Terminators:** For workflows initiated by a trigger rather than input data, use `C` as the input (e.g., `C2D+`). For workflows that consume input without producing data output, use the category of the medium where the state change occurs as the output (e.g., `D+2R` for physical/filesystem changes, `I2G` for UI changes).

**Naming Examples:**

*   `T2I`: e.g. Basic Text-to-Image.
*   `T2I_Basic_Text_to_Image`: Longer form name, not preferred, but needed if ambiguous with other workflows.  The most general functional version gets the most general name.
*   `T2I_Fast_SDTurbo`: Fast Text-to-Image using StableDiffusion Turbo.
*   `I+2T`: Describe multiple images (batch input) to produce multiple text descriptions.
*   `T+2I+`: Generate multiple/large images from multiple/large text inputs.
*   `D+2I+_Live_GPS_to_Map`: Converts a stream of GPS coordinates (D+) into a live updating visual map (I+).
*   `T2S_Fast_TTS_Preview`: Generates a quick, low-fidelity text-to-speech audio preview (S) from text (T).
*   `I+2D_Secure_FacialRec`: Performs facial recognition on multiple input images (I+) to produce structured data (D) about recognized individuals, potentially with security/privacy considerations.
*   `V2V_Live_StyleTransfer_Artistic`: Applies an artistic style transfer to a live video stream (V to V).
*   `T2I_v1.0`: Initial version of the Text-to-Image workflow.
*   `T2I_Fast_v1.0`: Updated version with faster processing using StableDiffusion Turbo.  The Fast feature tag qualifies it as a different version.
*   `T2I_Fast_SDTurbo_v1.0`: Clarifying the specific model used goes before specific version too.
*   `T2I_Fast_SDTurbo_2025-05-01`: Date-style versioning, if necessary
*   `C2D+_List_ComfyUI_Nodes`: Command/trigger generates a structured list (D+) of nodes. (Note: by convention, use `C` as the input when there are no explicit input triggers.)
*   `D+2D+_Delete_Files`: Consumes file data (D+) resulting in a filesystem (D+) state change.  (Deletions and sink operations should be classified according to the medium they're modifying)

### 3.2. Workflow Decomposition Principle

Combinations of multiple input categories (e.g., Text and Image to Image, potentially `TI2I`) are often a "code smell". It's generally preferable to decompose complex operations into simpler, chained workflows (e.g., `T2I` followed by `I2I`).

However, exploring direct `X2Y` transformations helps define the *atomic* capabilities available, even if they are later chained together in practice. Interactive layers coordinating multiple inputs might be represented differently (e.g., `G2I` for a game-like interface controlling image generation).

*Note:* General workflow configuration details and execution logic are considered part of the workflow program itself, not represented by 'C' or 'D' in the naming scheme unless code/data is the explicit *input* or *output* of the transformation step.

## 4. Classifying Examples

Here are examples of how different assets map to the categories, ordered by Category (T, I, V, M, S, C, D, G, R), then Ambiguity (least to most), then Quantity (singular to plural/large). Those near the bottom of each category are some of the more ambiguous examples which may be better suited to other categories depending on the circumstances and the specific focus of the workflow (e.g., treating a PDF as text T+ vs. its visual layout I+ vs. interactive elements G).

### T (Text):
*   **Prompt:** T (plain english text prompt)
*   **LLM Response:** T (until parsed into a more formal format like D or C)
*   **Paragraph:** T
*   **Image Caption:** T
*   **Plain Text File (.txt):** T or T+ (Depending on size)
*   **Book / Multiple Books:** T+ (text+)
*   **Chapter:** T+
*   **ComfyUI log:** T+
*   **Movie Script / Character Personality Script:** T+
*   **Word Document (.docx) / Google Doc:** T+ (Primarily text).
*   **Markdown File (.md):** T+ (Text with simple formatting markup).
*   **Choose-Your-Own-Adventure Book:** T+ (Primarily text, non-interactive branching).
*   **Github Readme:** T (or T+ depending on length)
*   **Investment Plan:** T+ ?
*   **Log File (e.g., server logs):** T+ (Large text) or D+ (if structured).
*   **Reddit Thread:** D or T+ (depending on structure vs. raw text focus)
*   **PDF Document:** I+ (image focus), T+ (text focus), D+ (forms), G (interactive); Default T+ if uncertain.

### I (Image):
*   **512x512 Image:** I (base expectation)
*   **Image Diff:** I (diff represented as an image)
*   **Image Mask / Video Frame:** I (singular image)
*   **Music Sheet (Scanned Image):** I (Image format).
*   **4k Image:** I or I+ (depending on specific handling needs)
*   **Image folder:** I+
*   **Architectural Drawing / Map:** I+ (typically large and detailed)
*   **Geographic Map Tiles (Raster):** I+ (Collection of image tiles).
*   **Satellite Imagery / Aerial Photo:** I+ (Large raster image data)
*   **Scanned Paper Map:** I+ (Raster image data)
*   **Font:** I+ (?) (Debatable - represents glyphs visually)
*   **QR Code:** I (Image format) encoding D (data) or C (URL).
*   **Photoshop/GIMP File (.psd, .xcf):** I+ (Complex layered image data) or G (if layer interaction focus).
*   **Circuit Diagram:** I, C, or D (depending on format specifics)

### V (Video):
*   **5 second Video / GIF:** V
*   **Video Frames:** V (collection of images treated as video)
*   **Live Video Stream (e.g., webcam):** V or V+
*   **5 minute Video:** V or V+ (depending on handling needs)
*   **Movie:** V+
*   **Screen Recording:** V+
*   **360-degree Video:** V+
*   **Motion Capture Data (.bvh, etc.):** V+ (movement sequence) or D+ (structured positional data).
*   **Video Game Replay File:** G+ (game state/inputs) or V+ (simple playback).

### M (Mesh):
*   **3D Printer Object / CAD Design / Blender Object:** M (mesh)
*   **Procedurally Generated Mesh (in memory):** M or M+
*   **Blender Scene:** M+
*   **Point Cloud Data (.ply, .las):** M+ (geometric points) or D+ (structured coordinates).
*   **Voxel Data (e.g., medical scans):** M+ (Volumetric grid).
*   **3D Scan Data (Raw Output):** M+ (Points or rough mesh).
*   **Fractal Geometry (3D):** M+
*   **Digital Elevation Model (DEM):** M+ (3D terrain mesh) or D+ (if raw grid data)
*   **3D City Model:** M+ (Complex 3D scene)
*   **Architectural Blueprint (CAD File):** M (Mesh data) or D (if opaque binary format).

### S (Sound/Speech):
*   **Song 30s / Speech / Song 3m:** S (sound/speech)
*   **Synthesized Musical Performance (from MIDI/Score):** S or S+
*   **Ultrasound Audio (Doppler, etc.):** S
*   **Morse Code (Audio Transmission):** S (Audio signal encoding T).
*   **Youtube Commentary:** S+ (audio)
*   **Audio Book:** S+
*   **Environmental Sound Recording (Field Recording):** S+
*   **Audio Spectrogram (as data array):** D+ (Structured frequency data, not S itself).

### C (Command/Code):
*   **System Trigger / Internal Call (implicit input):** C
*   **Command-line script / Python Script / Zapier API call:** C (command/code)
*   **HTML text element:** C
*   **URL / Filename:** C (single command/path)
*   **ComfyUI Node Settings:** C (specific configuration)
*   **CSS File:** C (Code defining presentation style).
*   **JavaScript File (.js):** C (Source code); the running app state might be G.
*   **Bash / Shell Script (.sh):** C (Command script).
*   **Torrent Magnet URI:** C (Command/identifier string).
*   **Github code repo:** C+
*   **HTML text file:** C+ (typically large)
*   **ComfyUI Workflow (JSON):** C+ (code/program definition)
*   **Android App:** C+
*   **Firmware Binary:** C+ (Low-level executable code).
*   **LaTeX Document (.tex):** C+ (Code/markup for document typesetting).
*   **Git Commit Diff:** C (Code change instructions) or T (if viewing textual changes).
*   **MIDI File:** C (Sequencer instructions) or D (Structured musical event data).
*   **SVG (Scalable Vector Graphics):** C (Code defining graphics) or I (rendered image).
*   **SQL Database Dump (.sql):** C+ (Large script of SQL commands) or D+ (representing the data).
*   **Spreadsheet with Macros:** C+ (Executable code is primary) or G (if UI interaction focus).

### D (Data, structured text):
*   **File (generic):** D (default for unspecified files)
*   **RAR File:** D
*   **Embeddings:** D (general data, could be specified like I-Embeddings, S-Embeddings etc.)
*   **Torrent File:** D (Structured metadata).
*   **VCard (.vcf):** D (Structured contact data).
*   **iCalendar (.ics):** D (Structured calendar data).
*   **Web Browser Cookie:** D (Small structured data).
*   **Security Certificate (.pem, .crt):** D (Structured identity/key data).
*   **Environment Variables (Set):** D (Set of simple key-value structured data).
*   **Color Palette File (.aco, .gpl):** D (Structured color data).
*   **Latitude/Longitude Coordinates:** D (Simple structured point data)
*   **Hard Drive Space Information:** D (Metadata about D+)
*   **JSON / CSV Table / requirements.txt:** D (structured data)
*   **Subtitle File (.srt, .vtt):** D (Structured text data with timing).
*   **LoRA:** D+ (data - consider them a general data format)
*   **AI model:** D+ (data+)
*   **CSV Tables / Database / File Folder / Disk Drive:** D+
*   **Trained Neural Network Weights:** D+ (Large numerical data block).
*   **User Profile (Settings, Preferences, History):** D+ (Structured user data).
*   **EEG Brain Scan Data:** D+ (Complex time-series data).
*   **DNA Sequence Data:** D+ (Structured sequence data).
*   **GeoJSON / Shapefile:** D+ (Structured geospatial data).
*   **ZIP / GZ / TAR Archive:** D+ (Structured container for other data).
*   **Windows Registry Hive:** D+ (Hierarchical configuration database).
*   **Scientific Data Format (e.g., HDF5, NetCDF):** D+ (Complex structured numerical data).
*   **RSS / Atom Feed:** D+ (Structured data feed, typically XML).
*   **System Process List:** D+ (Structured data about running processes).
*   **Network Packet Capture (.pcap):** D+ (Structured network communication data).
*   **Geographic Map Tiles (Vector):** D+ (Collection of structured vector data tiles).
*   **Route/Boundary Data (GPX, KML):** D+ (Structured lines/polygons)
*   **Email (.eml file / Standard Format):** D+ (Structured data with T+ body, headers, etc.).
*   **YAML / XML / INI Config Files:** D (Structured configuration data).
*   **Image Rating:** D (or T if minimally structured)
*   **Music Sheet (Digital Format e.g., MusicXML):** D (Structured data) or C (Executable instructions for sequencer).
*   **ComfyUI Metadata JSON:** D or C+ (data defining the program)
*   **Live Stock Market Ticker:** D+ (Streaming structured data).
*   **Live Sensor Feed (Temperature):** D+ (Structured, likely multiple readings) or R (if controlling robotics).
*   **GPS Coordinates (live feed):** D+ (Streaming point data)
*   **API Endpoint Definition (e.g., OpenAPI/Swagger spec):** D+ (Structured API definition) or C+ (executable contract).

### G (Game, interactive media):
*   **Shader:** G (minimal visual program)
*   **ComfyUI Interactive UI:** G
*   **Video Editor with UI:** G
*   **Interactive Fiction (Text Adventure):** G (Core is interactivity, consumes/produces T).
*   **PowerPoint (.pptx) / Google Slides:** G (Interactive presentation structure).
*   **Compiled Shader (Binary):** G (Minimal visual program, non-human-readable C).
*   **UI Element Deletion / State Change (result):** G
*   **Windows UI Program / Rendered HTML page / Image Viewer / IDE / Executable Program:** G (game/interactive - due to UI/interactive nature)
*   **Game-playing Agent:** G+
*   **Docker Image:** G+ (Packaged runnable environment); Dockerfile is C.
*   **Virtual Machine Disk Image (.vdi, .vmdk):** G+ (Runnable OS environment).
*   **AI Agent:** C+ or G+ (depending on interaction/presentation)

### R (Robotics, real-world):
*   **3D Printer Print:** R (robotics - real-world output)
*   **Robot Arm (Cobot) Commands / Drone Flightplan:** R
*   **Haptic Feedback Pattern:** R (Real-world physical output instruction).
*   **Cooking Recipe / Textile Recipe:** R (real-world instructions)
*   **Cookie Recipe (as Instructions):** R (Real-world instructions).
*   **Factory Plan:** R+

## 6. Conclusion

This taxonomy provides a framework for consistently describing and decomposing complex AI workflows into more manageable, reusable components based on their core data transformations.

